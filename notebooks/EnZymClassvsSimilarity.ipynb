{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnZymClass metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, matthews_corrcoef\n",
    "from scipy.stats import ttest_ind\n",
    "import itertools\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(y,yhat,label=3):\n",
    "    return round(precision_score(y,yhat,labels=[label],average='micro'),2)\n",
    "\n",
    "\n",
    "def get_recall(y,yhat,label=3):\n",
    "    return round(recall_score(y,yhat,labels=[label],average='micro'),2)\n",
    "\n",
    "\n",
    "def get_accuracy(y,yhat):\n",
    "    return round(accuracy_score(y,yhat),2)\n",
    "\n",
    "\n",
    "def get_mcc(y,yhat):\n",
    "    return round(matthews_corrcoef(y,yhat),2)\n",
    "\n",
    "\n",
    "def get_metrics(val_iter):\n",
    "    return get_precision(*val_iter), get_recall(*val_iter), get_accuracy(*val_iter), get_mcc(*val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pred_file = \"../data/results/ensemble_preds.csv\"\n",
    "\n",
    "valid_true_iter = itertools.islice(open(en_pred_file).readlines(), 0, 20000, 2)\n",
    "valid_pred_iter = itertools.islice(open(en_pred_file).readlines(), 1, 20000, 2)\n",
    "\n",
    "valid_true = [list(map(int, v.strip(\"\\n\").split(\",\"))) for v in list(valid_true_iter)]\n",
    "valid_pred = [list(map(int, v.strip(\"\\n\").split(\",\"))) for v in list(valid_pred_iter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of tuples, tuple values are prec, recall, acc and MCC\n",
    "mets = []\n",
    "\n",
    "for valid_iter in zip(valid_true, valid_pred):\n",
    "    met = get_metrics(valid_iter)\n",
    "    mets.append(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = [m[0] for m in mets]\n",
    "rec = [m[1] for m in mets]\n",
    "acc = [m[2] for m in mets]\n",
    "mcc = [m[3] for m in mets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_data = \"../similarity/results/model_sims.csv\"\n",
    "\n",
    "prec_sim = []\n",
    "rec_sim = []\n",
    "acc_sim = []\n",
    "mcc_sim = []\n",
    "\n",
    "with open(similarity_data, \"r\") as f:\n",
    "    for lines in f:\n",
    "        values = list(map(float, lines.strip().split(\",\")))\n",
    "        prec_sim.append(round(values[0], 2))\n",
    "        rec_sim.append(round(values[1], 2))\n",
    "        acc_sim.append(round(values[2], 2))\n",
    "        mcc_sim.append(round(values[3], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-test between EnZymClass and Similarity model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Ttest Results***\n",
      "-33.284 1.2160011429315447e-193\n",
      "-18.955 8.240325963485261e-74\n",
      "-24.595 6.615318198431384e-117\n",
      "-35.606 1.880889960590534e-215\n"
     ]
    }
   ],
   "source": [
    "tobj_acc = ttest_ind(acc_sim[:1000], acc[:1000], equal_var=True)\n",
    "tobj_prec = ttest_ind(prec_sim[:1000], prec[:1000], equal_var=True)\n",
    "tobj_rec = ttest_ind(rec_sim[:1000], rec[:1000], equal_var=True)\n",
    "tobj_mcc = ttest_ind(mcc_sim[:1000], mcc[:1000], equal_var=True)\n",
    "\n",
    "print(\"***Ttest Results***\")\n",
    "print(round(tobj_acc.statistic, 3), tobj_acc.pvalue)\n",
    "print(round(tobj_prec.statistic, 3), tobj_prec.pvalue)\n",
    "print(round(tobj_rec.statistic, 3), tobj_rec.pvalue)\n",
    "print(round(tobj_mcc.statistic, 3), tobj_mcc.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
