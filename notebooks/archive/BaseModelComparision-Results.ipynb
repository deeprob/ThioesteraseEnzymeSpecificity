{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append('../')\n",
    "from ensemble.model import Ensemble\n",
    "from baseModels.SVM.model import SVM\n",
    "from baseModels.GBC.model import GBC\n",
    "from baseModels.NN.model import NN\n",
    "from featEngg.online.kmerMethods.models import ngModel,gaangModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base:\n",
    "    def __init__(self,SVM=True,GBC=False,NN=False,pca_components=55,regCparam=30,\n",
    "        kernparam='rbf',nestparam=250,lrateparam=0.01,mdepthparam=3,ssampleparam=1,hlayer=(10,),\n",
    "        lrateinit=0.005,regparam=0.01,random_seed=None,optimizeQ=False,verboseQ=False):\n",
    "        \n",
    "        self.pca_components=pca_components\n",
    "        self.optimizeQ=optimizeQ\n",
    "        self.verboseQ=verboseQ\n",
    "        self.rs=random_seed\n",
    "        \n",
    "        if SVM:\n",
    "            self.regCparam=regCparam\n",
    "            self.kernparam=kernparam\n",
    "            \n",
    "        elif GBC:\n",
    "            self.nestparam=nestparam\n",
    "            self.lrateparam=lrateparam\n",
    "            self.mdepthparam=mdepthparam\n",
    "\n",
    "\n",
    "        elif NN:\n",
    "            self.hlayer=hlayer\n",
    "            self.lrateparam=lrateinit\n",
    "            self.reg=regparam\n",
    "\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('No model initiated')\n",
    "            \n",
    "    def get_SVM(self,Xtrain,Xvalid,ytrain,yvalid,Xtest=None):\n",
    "        return SVM(Xtrain,Xvalid,ytrain,yvalid,Xtest,pca_comp=self.pca_components,regC=self.regCparam,kern=self.kernparam,optimize=self.optimizeQ,verbose=self.verboseQ,random_seed=self.rs)\n",
    "    \n",
    "    def get_GBC(self,Xtrain,Xvalid,ytrain,yvalid,Xtest=None):\n",
    "        return GBC(Xtrain,Xvalid,ytrain,yvalid,Xtest,pca_comp=self.pca_components,nest=self.nestparam,lrate=self.lrateparam,mdepth=self.mdepthparam,optimize=self.optimizeQ,verbose=self.verboseQ,random_seed=self.rs)\n",
    "\n",
    "    def get_NN(self,Xtrain,Xvalid,ytrain,yvalid,Xtest=None):\n",
    "        return NN(Xtrain,Xvalid,ytrain,yvalid,Xtest,pca_comp=self.pca_components,hlayers=self.hlayer,lrateinit=self.lrateparam,regparam=self.reg,optimize=self.optimizeQ,verbose=self.verboseQ,random_seed=self.rs)\n",
    "\n",
    "\n",
    "class TEClassification(Base):\n",
    "    \n",
    "    def __init__(self,enzseqdata,testenzseqdata,labelfile,trainfeaturefiledirs,testfeaturefiledirs,model='SVM',random_seed=None,pca_components=55,n_models=17,validation_fraction=0.25):\n",
    "        \n",
    "        self.random_seed = random_seed\n",
    "        self.model=model\n",
    "        self.default_pca_components = pca_components\n",
    "        self.n_models = n_models\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.test = True if testfeaturefiledirs else False\n",
    "        \n",
    "        \n",
    "        #initialize super class\n",
    "        if self.model=='SVM':\n",
    "            super().__init__(random_seed=self.random_seed,optimizeQ=False)\n",
    "        else:\n",
    "            if self.model=='GBC':\n",
    "                super().__init__(random_seed=self.random_seed,SVM=False,GBC=True)\n",
    "            elif self.model=='NN':\n",
    "                super().__init__(random_seed=self.random_seed,SVM=False,NN=True)\n",
    "            else:\n",
    "                raise ValueError('Wrong Model Assigned')\n",
    "        \n",
    "        self.object_map = {'SVM':self.get_SVM,'NN':self.get_NN,'GBC':self.get_GBC}\n",
    "        \n",
    "        # original data based on which everything is obtained\n",
    "        df1 = pd.read_csv(enzseqdata,header=None)\n",
    "        df2 = pd.read_csv(labelfile,header=None)\n",
    "        self.train_df = df1.merge(df2,on=0)\n",
    "        \n",
    "        self.enz_names = self.train_df[0].values\n",
    "        self.X = self.train_df.iloc[:,1].values\n",
    "        self.y = self.train_df.iloc[:,-1].values\n",
    "        \n",
    "        # training and validation data for general use\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid,self.enz_train,self.enz_valid = train_test_split(self.X, self.y,self.enz_names, test_size=self.validation_fraction, random_state=self.random_seed)\n",
    "        \n",
    "        self.label_file = labelfile\n",
    "        \n",
    "        # test data\n",
    "        if self.test:\n",
    "            self.test_df = pd.read_csv(testenzseqdata,header=None)\n",
    "            self.testenz_names = self.test_df[0].values\n",
    "            self.X_test = self.test_df.iloc[:,1].values\n",
    "        else:\n",
    "            self.X_test=None\n",
    "            \n",
    "            \n",
    "        # kmer and gaakmer\n",
    "        ng = ngModel(self.X_train,self.X_valid,self.X_test)\n",
    "        gaang = gaangModel(self.X_train,self.X_valid,self.X_test)\n",
    "        kmernames = ['kmer','gaakmer']\n",
    "        kmerObjs = [self.get_model_online(ng.Xtrain,ng.Xvalid,self.y_train,self.y_valid,ng.Xtest),self.get_model_online(gaang.Xtrain,gaang.Xvalid,self.y_train,self.y_valid,gaang.Xtest)]\n",
    "\n",
    "        \n",
    "        #generate a list of names from the directories\n",
    "        trainfeatfiles = [d+f.name for d in trainfeaturefiledirs for f in os.scandir(d) if f.name.endswith('.csv.gz')]            \n",
    "        self.featnames = [f.name.replace('.csv.gz','') for d in trainfeaturefiledirs for f in os.scandir(d) if f.name.endswith('.csv.gz')]\n",
    "        \n",
    "        if self.test:\n",
    "            testfeatfiles = [d+f.name for d in testfeaturefiledirs for f in os.scandir(d) if f.name.endswith('.csv.gz')]\n",
    "            func_iter = list(zip(trainfeatfiles,testfeatfiles))\n",
    "            assert [f.name for d in trainfeaturefiledirs for f in os.scandir(d) if f.name.endswith('.csv.gz')]==[f.name for d in testfeaturefiledirs for f in os.scandir(d) if f.name.endswith('.csv.gz')]\n",
    "            self.objects=list(itertools.starmap(self.get_model_offline,func_iter))\n",
    "\n",
    "        else:\n",
    "            # getting all SVM objects together\n",
    "            self.objects = list(map(self.get_model_offline,trainfeatfiles))\n",
    "            \n",
    "        self.featnames.extend(kmernames)\n",
    "        self.objects.extend(kmerObjs)\n",
    "            \n",
    "        \n",
    "        # select only the best models based on training or validation\n",
    "        self.best_idx,self.best_models = self.select_top_models(self.objects)\n",
    "        self.best_model_names = np.array(self.featnames)[self.best_idx]\n",
    "        \n",
    "        # getting all model predictions together for ensemble\n",
    "        if not self.test:\n",
    "            self.all_model_preds = [o.ypredvalid for o in self.best_models]\n",
    "            self.en = Ensemble(self.all_model_preds,self.y_valid)\n",
    "            self.precision = precision_score(self.y_valid,self.en.preds,labels=[3],average='micro')\n",
    "            self.recall = recall_score(self.y_valid,self.en.preds,labels=[3],average='micro')\n",
    "            \n",
    "        else:\n",
    "            self.all_model_preds = [o.yhattest for o in self.best_models]\n",
    "            self.en = Ensemble(self.all_model_preds)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def get_model_online(self,X_train,X_valid,y_train,y_valid,X_test=None):\n",
    "\n",
    "        if X_train.shape[1]<self.default_pca_components:\n",
    "            self.pca_components = int(0.75*X_train.shape[1])\n",
    "        else:\n",
    "            self.pca_components=self.default_pca_components\n",
    "            \n",
    "        if self.test:\n",
    "            obj = self.object_map[self.model](X_train,X_valid,y_train,y_valid,X_test)\n",
    "        else:\n",
    "            obj = self.object_map[self.model](X_train,X_valid,y_train,y_valid)\n",
    "        return obj\n",
    "    \n",
    "    \n",
    "    def get_model_offline(self,featfilename,testfeatfilename=None):\n",
    "        \n",
    "        df1 = pd.read_csv(featfilename,header=None)\n",
    "        df2 = pd.read_csv(self.label_file,header=None)\n",
    "        df_feat = df1.merge(df2,on=0).set_index(0)\n",
    "        df_feat_train = df_feat.loc[self.enz_train]\n",
    "        df_feat_valid = df_feat.loc[self.enz_valid]\n",
    "        X_train_feat,y_train_feat = df_feat_train.iloc[:,0:-1].values,df_feat_train.iloc[:,-1].values\n",
    "        X_valid_feat,y_valid_feat = df_feat_valid.iloc[:,0:-1].values,df_feat_valid.iloc[:,-1].values\n",
    "\n",
    "        if X_train_feat.shape[1]<self.default_pca_components:\n",
    "            self.pca_components = int(0.75*X_train_feat.shape[1])\n",
    "        else:\n",
    "            self.pca_components=self.default_pca_components\n",
    "            \n",
    "        if self.test:\n",
    "            df_feat_test = pd.read_csv(testfeatfilename,header=None).set_index(0)\n",
    "            X_test_feat = df_feat_test.loc[self.testenz_names].values\n",
    "            if X_train_feat.shape[1] != X_test_feat.shape[1]:\n",
    "                print(featfilename)\n",
    "            obj = self.object_map[self.model](X_train_feat,X_valid_feat,y_train_feat,y_valid_feat,X_test_feat)\n",
    "        else:\n",
    "            obj = self.object_map[self.model](X_train_feat,X_valid_feat,y_train_feat,y_valid_feat)\n",
    "        return obj\n",
    "\n",
    "        \n",
    "    def select_top_models(self,Os):\n",
    "        o_valid_accs = [o.acc_valid for o in Os] #if self.test else [o.acc_train for o in Os] \n",
    "        sorted_idx = np.argsort(o_valid_accs)[::-1]\n",
    "        best_idx = sorted_idx[:self.n_models]\n",
    "        return best_idx,np.array(Os)[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(y,yhat):\n",
    "    return round(precision_score(y,yhat,labels=[3],average='micro'),2)\n",
    "\n",
    "\n",
    "def get_recall(y,yhat):\n",
    "    return round(recall_score(y,yhat,labels=[3],average='micro'),2)\n",
    "\n",
    "\n",
    "def get_f1_score(y,yhat):\n",
    "    return round(f1_score(y,yhat,average='micro'),2)\n",
    "\n",
    "def get_accuracy(y,yhat):\n",
    "    return round(accuracy_score(y,yhat),2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 313 ms, total: 1.33 s\n",
      "Wall time: 6h 48min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__=='__main__':\n",
    "    # Sequence and label files \n",
    "    enz_file = '../data/seq/EnzymeSequence.csv'\n",
    "    label_file = '../data/label/EnzymeLabelsMultiClass.csv'\n",
    "\n",
    "    # Feature dir for iFeature,kernel,pssm \n",
    "    ifeatdatadir = '../featEngg/offline/ifeatMethods/data/featvec/trainfiles/'\n",
    "    kerneldatadir = '../featEngg/offline/kernelMethods/data/featvec/trainfiles/'\n",
    "    pssmdatadir = '../featEngg/offline/pssmMethods/data/featvec/trainfiles/'\n",
    "\n",
    "    trainfeatdirs = [ifeatdatadir,kerneldatadir,pssmdatadir]\n",
    "\n",
    "    \n",
    "    def multi_func(rs):\n",
    "        te_i = TEClassification(enz_file,None,label_file,trainfeatdirs,None,random_seed=rs)\n",
    "        return te_i.precision,te_i.en.acc    \n",
    "\n",
    "    def multi_func_NN(rs):\n",
    "        te_i = TEClassification(enz_file,None,label_file,trainfeatdirs,None,model='NN',random_seed=rs,n_models=5)\n",
    "        return te_i.precision,te_i.en.acc    \n",
    "\n",
    "    def multi_func_GBC(rs):\n",
    "        te_i = TEClassification(enz_file,None,label_file,trainfeatdirs,None,model='GBC',random_seed=rs,n_models=5)\n",
    "        return te_i.precision,te_i.recall,te_i.en.acc    \n",
    "\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    \n",
    "    metrics_GBC = list(pool.map(multi_func_GBC,range(10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_base = '../data/results/basemodel_comp.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model_report(model_name,model_metrics):\n",
    "    datadict = {'min precision':[],'min recall':[],'min accuracy':[],\n",
    "               'max precision':[],'max recall':[],'max accuracy':[],\n",
    "               'mean precision':[],'mean recall':[],'mean accuracy':[],\n",
    "               'std precision':[],'std recall':[],'std accuracy':[]}\n",
    "    \n",
    "    index_names = [model_name]\n",
    "    \n",
    "    for m_metrics in model_metrics:\n",
    "        \n",
    "#         index_names.append(mn)\n",
    "        \n",
    "        precs = [m[0] for m in m_metrics]\n",
    "        recalls = [m[1] for m in m_metrics]\n",
    "        accs = [m[2] for m in m_metrics]\n",
    "        \n",
    "\n",
    "        datadict['mean precision'].append(np.mean(precs))\n",
    "        datadict['mean recall'].append(np.mean(recalls))\n",
    "#         datadict['mean f1_score'].append(np.mean(f1_scores))\n",
    "        datadict['mean accuracy'].append(np.mean(accs))\n",
    "\n",
    "        datadict['min precision'].append(min(precs))\n",
    "        datadict['min recall'].append(min(recalls))\n",
    "#         datadict['min f1_score'].append(min(f1_scores))\n",
    "        datadict['min accuracy'].append(min(accs))\n",
    "\n",
    "        datadict['max precision'].append(max(precs))\n",
    "        datadict['max recall'].append(max(recalls))\n",
    "#         datadict['max f1_score'].append(max(f1_scores))\n",
    "        datadict['max accuracy'].append(max(accs))\n",
    "\n",
    "        datadict['std precision'].append(np.std(precs))\n",
    "        datadict['std recall'].append(np.std(recalls))\n",
    "#         datadict['std f1_score'].append(np.std(f1_scores))\n",
    "        datadict['std accuracy'].append(np.std(accs))\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(datadict,index=index_names)\n",
    "    return df.to_csv(filename_base,mode='a',index=True,header=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_model_report('GBC',[metrics_GBC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
