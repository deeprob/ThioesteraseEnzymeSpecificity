{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from itertools import starmap,groupby\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append('../')\n",
    "from baseModels.SVM.model import SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class features:\n",
    "    def __init__(self):\n",
    "        feature_files_dir = '../featEngg/'\n",
    "        self.feature_dict = {}\n",
    "        self.get_feature_dict(feature_files_dir)\n",
    "        pass\n",
    "    \n",
    "    def get_feature_dict(self,feature_files_dir):\n",
    "        for algo_type in os.scandir(feature_files_dir):\n",
    "            if algo_type.is_dir():\n",
    "                for feat_type in os.scandir(feature_files_dir+algo_type.name+'/'):\n",
    "                    if feat_type.name.endswith('Methods'):\n",
    "                        if feat_type.name == 'kmerMethods':\n",
    "                            self.feature_dict[algo_type.name] = {feat_type.name:{'kmer':None,'gaakmer':None}}\n",
    "                        else:\n",
    "                            for file in os.scandir(feature_files_dir+algo_type.name+'/'+feat_type.name+'/data/featvec/trainfiles/'):\n",
    "                                feat_name = file.name.replace('.csv.gz','')\n",
    "                                if algo_type.name not in self.feature_dict:\n",
    "                                    self.feature_dict[algo_type.name] = {feat_type.name:{feat_name:feature_files_dir+algo_type.name+'/'+feat_type.name+'/data/featvec/trainfiles/'+file.name}}\n",
    "                                else:\n",
    "                                    if feat_type.name not in self.feature_dict[algo_type.name]:\n",
    "                                        self.feature_dict[algo_type.name][feat_type.name] = {feat_name:feature_files_dir+algo_type.name+'/'+feat_type.name+'/data/featvec/trainfiles/'+file.name}\n",
    "                                    else:\n",
    "                                        self.feature_dict[algo_type.name][feat_type.name][feat_name] = feature_files_dir+algo_type.name+'/'+feat_type.name+'/data/featvec/trainfiles/'+file.name\n",
    "        return\n",
    "    \n",
    "    def get_feat_iter(self,iters_to_repeat):\n",
    "        algo_type = []\n",
    "        feat_type = []\n",
    "        feat_name = []\n",
    "        for feat_types in self.feature_dict['offline'].keys():\n",
    "            for feat_names in self.feature_dict['offline'][feat_types].keys():\n",
    "                algo_type.append('offline')\n",
    "                feat_type.append(feat_types)\n",
    "                feat_name.append(feat_names)\n",
    "        args_list = [(fn,ft,at,it) for at,ft,fn in zip(algo_type,feat_type,feat_name) for it in range(iters_to_repeat)]\n",
    "        return args_list\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class feature_hpopt(features):\n",
    "    def __init__(self,feature_name='dp_pssm',feature_type='pssmMethods',algo_type='offline',random_seed=None,pca_components=45):\n",
    "        \n",
    "        super().__init__()\n",
    "        original_seq_file = '../data/SeqFile/EnzymeSequence.csv'\n",
    "        label_file = '../data/LabelFiles/EnzymeLabelsMultiClass.csv'\n",
    "        self.random_seed = random_seed\n",
    "        self.default_pca_components = pca_components\n",
    "        \n",
    "        # original data based on which everything is obtained\n",
    "        df1 = pd.read_csv(original_seq_file,header=None)\n",
    "        df2 = pd.read_csv(label_file,header=None)\n",
    "        self.train_df = df1.merge(df2,on=0)\n",
    "        \n",
    "        self.enz_names = self.train_df[0].values\n",
    "        self.X = self.train_df.iloc[:,1].values\n",
    "        self.y = self.train_df.iloc[:,-1].values\n",
    "        \n",
    "        # training and validation data for general use\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid,self.enz_train,self.enz_valid = train_test_split(self.X, self.y,self.enz_names, test_size=0.25, random_state=self.random_seed)\n",
    "\n",
    "        self.label_file = label_file\n",
    "        self.seq_file = original_seq_file\n",
    "        \n",
    "        self.hpopt_feature_file = self.feature_dict[algo_type][feature_type][feature_name]\n",
    "        self.model = self.get_offline_model(self.hpopt_feature_file)\n",
    "        \n",
    "    def get_offline_model(self,featfilename,testfeatfilename=None):\n",
    "        \n",
    "        df1 = pd.read_csv(featfilename,header=None)\n",
    "        df2 = pd.read_csv(self.label_file,header=None)\n",
    "        df_feat = df1.merge(df2,on=0).set_index(0)\n",
    "        df_feat_train = df_feat.loc[self.enz_train]\n",
    "        df_feat_valid = df_feat.loc[self.enz_valid]\n",
    "        X_train_feat,y_train_feat = df_feat_train.iloc[:,0:-1].values,df_feat_train.iloc[:,-1].values\n",
    "        X_valid_feat,y_valid_feat = df_feat_valid.iloc[:,0:-1].values,df_feat_valid.iloc[:,-1].values\n",
    "\n",
    "        if X_train_feat.shape[1]<self.default_pca_components:\n",
    "            self.pca_components = int(0.75*X_train_feat.shape[1])\n",
    "        else:\n",
    "            self.pca_components=self.default_pca_components\n",
    "            \n",
    "        if testfeatfilename is not None:\n",
    "            df_feat_test = pd.read_csv(testfeatfilename,header=None).set_index(0)\n",
    "            X_test_feat = df_feat_test.loc[self.testenz_names].values\n",
    "            if X_train_feat.shape[1] != X_test_feat.shape[1]:\n",
    "                print(featfilename)\n",
    "            obj = SVM(X_train_feat,X_valid_feat,y_train_feat,y_valid_feat,X_test_feat)\n",
    "        else:\n",
    "            obj = SVM(X_train_feat,X_valid_feat,y_train_feat,y_valid_feat,verbose=False,optimize=True,pca_comp=self.pca_components,multi_jobs=False)\n",
    "        return obj\n",
    "    \n",
    "    def get_best_hps(self):\n",
    "        return tuple(self.model.grid.best_params_.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_hp_func(feat_name,feat_type,algo_type,rs):\n",
    "    myfeat = feature_hpopt(feat_name,feat_type,algo_type,random_seed=rs)\n",
    "    return myfeat.get_best_hps()\n",
    "\n",
    "def most_frequent(arr):\n",
    "    count = Counter(arr)\n",
    "    most_freq = count.most_common(1)[0][0]\n",
    "    return most_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argument_iter):\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    best_hps = list(pool.starmap(feat_hp_func,argument_iter))\n",
    "    best_hp_dict = {}\n",
    "    for feat_name,feat_info in groupby(zip(argument_iter,best_hps),key=lambda x: x[0][0]):\n",
    "        best_hp_list = [hp[1] for hp in list(feat_info)]\n",
    "        best_regC = most_frequent([x[0] for x in best_hp_list])\n",
    "        best_kernel = most_frequent([x[1] for x in best_hp_list])\n",
    "        best_ncomp = most_frequent([x[2] for x in best_hp_list])\n",
    "        best_hp_dict[feat_name] = {'regC':best_regC,'kernel':best_kernel,'pca_comp':best_ncomp}\n",
    "    return best_hp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 8.33 s, total: 19.4 s\n",
      "Wall time: 4h 16min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__=='__main__':\n",
    "    feat = features()\n",
    "    args_list = feat.get_feat_iter(100)   \n",
    "    hps = main(args_list)\n",
    "    with open('../data/SimResults/HyperParameterOptimization/IndHPOpt.csv','w') as f:\n",
    "        f.write('feat_name,regC,kernel,pca_comp')\n",
    "        f.write('\\n')\n",
    "        for key in hps.keys():\n",
    "            f.write(f\"{key},{hps[key]['regC']},{hps[key]['kernel']},{hps[key]['pca_comp']}\")\n",
    "            f.write('\\n')\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
